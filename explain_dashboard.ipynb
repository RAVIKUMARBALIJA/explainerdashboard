{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statutory-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import explainerdashboard as eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coupled-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "robust-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer,ExplainerDashboard\n",
    "from explainerdashboard.datasets import titanic_survive,titanic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test = titanic_survive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stunning-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_names,test_names=titanic_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beautiful-wesley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869753979739508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lightweight-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rapid-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "responsible-contributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stylish-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ClassifierExplainer in module explainerdashboard.explainers:\n",
      "\n",
      "class ClassifierExplainer(BaseExplainer)\n",
      " |  ClassifierExplainer(model, X: pandas.core.frame.DataFrame, y: pandas.core.series.Series = None, permutation_metric: Callable = <function roc_auc_score at 0x00000266119090D0>, shap: str = 'guess', X_background: pandas.core.frame.DataFrame = None, model_output: str = 'probability', cats: Union[List, Dict] = None, cats_notencoded: Dict = None, idxs: pandas.core.indexes.base.Index = None, index_name: str = None, target: str = None, descriptions: Dict = None, n_jobs: int = None, permutation_cv: int = None, cv: int = None, na_fill: float = -999, precision: str = 'float64', labels: List = None, pos_label: int = 1)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ClassifierExplainer\n",
      " |      BaseExplainer\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model, X: pandas.core.frame.DataFrame, y: pandas.core.series.Series = None, permutation_metric: Callable = <function roc_auc_score at 0x00000266119090D0>, shap: str = 'guess', X_background: pandas.core.frame.DataFrame = None, model_output: str = 'probability', cats: Union[List, Dict] = None, cats_notencoded: Dict = None, idxs: pandas.core.indexes.base.Index = None, index_name: str = None, target: str = None, descriptions: Dict = None, n_jobs: int = None, permutation_cv: int = None, cv: int = None, na_fill: float = -999, precision: str = 'float64', labels: List = None, pos_label: int = 1)\n",
      " |      Explainer for classification models. Defines the shap values for\n",
      " |      each possible class in the classification.\n",
      " |      \n",
      " |      You assign the positive label class afterwards with e.g. explainer.pos_label=0\n",
      " |      \n",
      " |      In addition defines a number of plots specific to classification problems\n",
      " |      such as a precision plot, confusion matrix, roc auc curve and pr auc curve.\n",
      " |      \n",
      " |      Compared to BaseExplainer defines two additional parameters\n",
      " |      \n",
      " |      Args:\n",
      " |          model: a model with a scikit-learn compatible .fit and .predict methods\n",
      " |          X (pd.DataFrame): a pd.DataFrame with your model features\n",
      " |          y (pd.Series): Dependent variable of your model, defaults to None\n",
      " |          permutation_metric (function or str): is a scikit-learn compatible \n",
      " |              metric function (or string). Defaults to r2_score\n",
      " |          shap (str): type of shap_explainer to fit: 'tree', 'linear', 'kernel'. \n",
      " |              Defaults to 'guess'.\n",
      " |          X_background (pd.DataFrame): background X to be used by shap \n",
      " |              explainers that need a background dataset (e.g. shap.KernelExplainer\n",
      " |              or shap.TreeExplainer with boosting models and \n",
      " |              model_output='probability').\n",
      " |          model_output (str): model_output of shap values, either 'raw', \n",
      " |              'logodds' or 'probability'. Defaults to 'raw' for regression and\n",
      " |              'probability' for classification.\n",
      " |          cats ({dict, list}): dict of features that have been \n",
      " |              onehotencoded. e.g. cats={'Sex':['Sex_male', 'Sex_female']}. \n",
      " |              If all encoded columns are underscore-seperated (as above), can simply\n",
      " |              pass a list of prefixes: cats=['Sex']. Allows to \n",
      " |              group onehot encoded categorical variables together in \n",
      " |              various plots. Defaults to None.\n",
      " |          cats_notencoded (dict): value to display when all onehot encoded\n",
      " |              columns are equal to zero. Defaults to 'NOT_ENCODED' for each\n",
      " |              onehot col.\n",
      " |          idxs (pd.Series): list of row identifiers. Can be names, id's, etc. \n",
      " |              Defaults to X.index.\n",
      " |          index_name (str): identifier for row indexes. e.g. index_name='Passenger'.\n",
      " |              Defaults to X.index.name or idxs.name.\n",
      " |          target: name of the predicted target, e.g. \"Survival\", \n",
      " |              \"Ticket price\", etc. Defaults to y.name.\n",
      " |          n_jobs (int): for jobs that can be parallelized using joblib,\n",
      " |              how many processes to split the job in. For now only used\n",
      " |              for calculating permutation importances. Defaults to None.\n",
      " |          permutation_cv (int): Deprecated! Use parameter cv instead! \n",
      " |              (now also works for calculating metrics)\n",
      " |          cv (int): If not None then permutation importances and metrics\n",
      " |              will get calculated using cross validation across X. Use this\n",
      " |              when you are passing the training set to the explainer. \n",
      " |              Defaults to None.\n",
      " |          na_fill (int): The filler used for missing values, defaults to -999.\n",
      " |          precision: precision with which to store values. Defaults to \"float64\".\n",
      " |          labels(list): list of str labels for the different classes, \n",
      " |                      defaults to e.g. ['0', '1'] for a binary classification\n",
      " |          pos_label: class that should be used as the positive class, \n",
      " |                      defaults to 1\n",
      " |  \n",
      " |  calculate_properties(self, include_interactions=True)\n",
      " |      calculate all lazily calculated properties of explainer\n",
      " |      \n",
      " |      Args:\n",
      " |        include_interactions:  (Default value = True)\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  confusion_matrix(self, cutoff=0.5, binary=True, pos_label=None)\n",
      " |  \n",
      " |  cutoff_from_percentile(self, percentile, pos_label=None)\n",
      " |      The cutoff equivalent to the percentile given\n",
      " |      \n",
      " |      For example if you want the cutoff that splits the highest 20% \n",
      " |      pred_proba from the lowest 80%, you would set percentile=0.8 \n",
      " |      and get the correct cutoff.\n",
      " |      \n",
      " |      Args:\n",
      " |        percentile(float):  percentile to convert to cutoff \n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        cutoff\n",
      " |  \n",
      " |  get_classification_df(self, cutoff=0.5, pos_label=None)\n",
      " |      Returns a dataframe with number of observations in each class above\n",
      " |      and below the cutoff.\n",
      " |      \n",
      " |      Args:\n",
      " |          cutoff (float, optional): Cutoff to split on. Defaults to 0.5.\n",
      " |          pos_label (int, optional): Pos label to generate dataframe for. \n",
      " |              Defaults to self.pos_label.\n",
      " |      \n",
      " |      Returns:\n",
      " |          pd.DataFrame\n",
      " |  \n",
      " |  get_liftcurve_df(self, pos_label=None)\n",
      " |      returns a pd.DataFrame with data needed to build a lift curve\n",
      " |      \n",
      " |      Args:\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  get_precision_df(self, bin_size=None, quantiles=None, multiclass=False, round=3, pos_label=None)\n",
      " |      dataframe with predicted probabilities and precision\n",
      " |      \n",
      " |      Args:\n",
      " |        bin_size(float, optional, optional): group predictions in bins of size bin_size, defaults to 0.1\n",
      " |        quantiles(int, optional, optional): group predictions in evenly sized quantiles of size quantiles, defaults to None\n",
      " |        multiclass(bool, optional, optional): whether to calculate precision for every class (Default value = False)\n",
      " |        round:  (Default value = 3)\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame: precision_df\n",
      " |  \n",
      " |  get_shap_row(self, index=None, X_row=None, pos_label=None)\n",
      " |  \n",
      " |  get_shap_values_df(self, pos_label=None)\n",
      " |      SHAP Values\n",
      " |  \n",
      " |  keep_shap_pos_label_only(self, pos_label=None)\n",
      " |      drops the shap values and shap_interaction values for all labels \n",
      " |      except pos_label in order to save on memory usage for multi class classifiers\n",
      " |  \n",
      " |  mean_abs_shap_df(self, pos_label=None)\n",
      " |      mean absolute SHAP values\n",
      " |  \n",
      " |  metrics(self, cutoff: float = 0.5, show_metrics: List[Union[str, Callable]] = None, pos_label: int = None)\n",
      " |      returns a dict with useful metrics for your classifier:\n",
      " |      \n",
      " |      accuracy, precision, recall, f1, roc auc, pr auc, log loss\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff(float): cutoff used to calculate metrics (Default value = 0.5)\n",
      " |        show_metrics (List): list of metrics to display in order. Defaults\n",
      " |              to None, displaying all metrics.\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        dict\n",
      " |  \n",
      " |  metrics_descriptions(self, cutoff=0.5, round=3, pos_label=None)\n",
      " |      Returns a metrics dict with the value replaced with a\n",
      " |      description/interpretation of the value\n",
      " |      \n",
      " |      Args:\n",
      " |          cutoff (float, optional): Cutoff for calculating the metrics. Defaults to 0.5.\n",
      " |          round (int, optional): Round to apply to floats. Defaults to 3.\n",
      " |          pos_label (None, optional): positive label. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict\n",
      " |  \n",
      " |  percentile_from_cutoff(self, cutoff, pos_label=None)\n",
      " |      The percentile equivalent to the cutoff given\n",
      " |      \n",
      " |      For example if set the cutoff at 0.8, then what percentage\n",
      " |      of pred_proba is above this cutoff?\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff (float):  cutoff to convert to percentile\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        percentile\n",
      " |  \n",
      " |  permutation_importances(self, pos_label=None)\n",
      " |      Permutation importances\n",
      " |  \n",
      " |  plot_classification(self, cutoff=0.5, percentage=True, pos_label=None)\n",
      " |      plot showing a barchart of the classification result for cutoff\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff(float, optional): cutoff of positive class to calculate lift \n",
      " |                  (Default value = 0.5)\n",
      " |        percentage(bool, optional): display percentages instead of counts, \n",
      " |                  defaults to True\n",
      " |        pos_label: positive label to display, defaults to self.pos_label\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly fig\n",
      " |  \n",
      " |  plot_confusion_matrix(self, cutoff=0.5, normalized=False, binary=False, pos_label=None)\n",
      " |      plot of a confusion matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff(float, optional, optional): cutoff of positive class to \n",
      " |                  calculate confusion matrix for, defaults to 0.5\n",
      " |        normalized(bool, optional, optional): display percentages instead \n",
      " |                  of counts , defaults to False\n",
      " |        binary(bool, optional, optional): if multiclass display one-vs-rest \n",
      " |                  instead, defaults to False\n",
      " |        pos_label: positive label to display, defaults to self.pos_label\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly fig\n",
      " |  \n",
      " |  plot_cumulative_precision(self, percentile=None, pos_label=None)\n",
      " |      plot cumulative precision\n",
      " |      \n",
      " |      returns a cumulative precision plot, which is a slightly different\n",
      " |      representation of a lift curve.\n",
      " |      \n",
      " |      Args:\n",
      " |        pos_label: positive label to display, defaults to self.pos_label\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly fig\n",
      " |  \n",
      " |  plot_lift_curve(self, cutoff=None, percentage=False, add_wizard=True, round=2, pos_label=None)\n",
      " |      plot of a lift curve.\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff(float, optional): cutoff of positive class to calculate lift \n",
      " |                  (Default value = None)\n",
      " |        percentage(bool, optional): display percentages instead of counts, \n",
      " |                  defaults to False\n",
      " |        add_wizard (bool, optional): Add a line indicating how a perfect model \n",
      " |                  would perform (\"the wizard\"). Defaults to True.\n",
      " |        round: number of digits to round to (Default value = 2)\n",
      " |        pos_label: positive label to display, defaults to self.pos_label\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly fig\n",
      " |  \n",
      " |  plot_pr_auc(self, cutoff=0.5, pos_label=None)\n",
      " |      plots PR_AUC curve.\n",
      " |      \n",
      " |      the precision and recall of particular cutoff is displayed in crosshairs.\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff: cutoff value to be included in plot (Default value = 0.5)\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  plot_precision(self, bin_size=None, quantiles=None, cutoff=None, multiclass=False, pos_label=None)\n",
      " |      plot precision vs predicted probability\n",
      " |      \n",
      " |      plots predicted probability on the x-axis and observed precision (fraction of actual positive\n",
      " |      cases) on the y-axis.\n",
      " |      \n",
      " |      Should pass either bin_size fraction of number of quantiles, but not both.\n",
      " |      \n",
      " |      Args:\n",
      " |        bin_size(float, optional):  size of the bins on x-axis (e.g. 0.05 for 20 bins)\n",
      " |        quantiles(int, optional): number of equal sized quantiles to split \n",
      " |                  the predictions by e.g. 20, optional)\n",
      " |        cutoff: cutoff of model to include in the plot (Default value = None)\n",
      " |        multiclass: whether to display all classes or only positive class, \n",
      " |                  defaults to False\n",
      " |        pos_label: positive label to display, defaults to self.pos_label\n",
      " |      \n",
      " |      Returns:\n",
      " |        Plotly fig\n",
      " |  \n",
      " |  plot_prediction_result(self, index=None, X_row=None, showlegend=True)\n",
      " |      Returns a piechart with the predicted probabilities distribution\n",
      " |      \n",
      " |      Args:\n",
      " |          index ({int, str}): Index for which to display prediction\n",
      " |          X_row (pd.DataFrame): single row of an input dataframe, e.g.\n",
      " |              explainer.X.iloc[[0]]\n",
      " |          showlegend (bool, optional): Display legend. Defaults to False.\n",
      " |      \n",
      " |      Returns:\n",
      " |          plotly.fig\n",
      " |  \n",
      " |  plot_roc_auc(self, cutoff=0.5, pos_label=None)\n",
      " |      plots ROC_AUC curve.\n",
      " |      \n",
      " |      The TPR and FPR of a particular cutoff is displayed in crosshairs.\n",
      " |      \n",
      " |      Args:\n",
      " |        cutoff: cutoff value to be included in plot (Default value = 0.5)\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  pos_label_index(self, pos_label)\n",
      " |      return int index of pos_label_str\n",
      " |  \n",
      " |  pr_auc_curve(self, pos_label=None)\n",
      " |      Returns a dict with output from sklearn.metrics.precision_recall_curve() for pos_label:\n",
      " |      fpr, tpr, thresholds, score\n",
      " |  \n",
      " |  pred_percentiles(self, pos_label=None)\n",
      " |      returns ranks for pos_label class\n",
      " |  \n",
      " |  pred_probas(self, pos_label=None)\n",
      " |      returns pred_proba for pos_label class\n",
      " |  \n",
      " |  prediction_result_df(self, index=None, X_row=None, add_star=True, logodds=False, round=3)\n",
      " |      returns a table with the predicted probability for each label for index\n",
      " |      \n",
      " |      Args:\n",
      " |          index ({int, str}): index\n",
      " |          add_star(bool): add a star to the observed label\n",
      " |          round (int): rounding to apply to pred_proba float\n",
      " |      \n",
      " |      Returns:\n",
      " |          pd.DataFrame\n",
      " |  \n",
      " |  random_index(self, y_values=None, return_str=False, pred_proba_min=None, pred_proba_max=None, pred_percentile_min=None, pred_percentile_max=None, pos_label=None)\n",
      " |      random index satisfying various constraint\n",
      " |      \n",
      " |      Args:\n",
      " |        y_values: list of labels to include (Default value = None)\n",
      " |        return_str: return str from self.idxs (Default value = False)\n",
      " |        pred_proba_min: minimum pred_proba (Default value = None)\n",
      " |        pred_proba_max: maximum pred_proba (Default value = None)\n",
      " |        pred_percentile_min: minimum pred_proba percentile (Default value = None)\n",
      " |        pred_percentile_max: maximum pred_proba percentile (Default value = None)\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        index\n",
      " |  \n",
      " |  roc_auc_curve(self, pos_label=None)\n",
      " |      Returns a dict with output from sklearn.metrics.roc_curve() for pos_label:\n",
      " |      fpr, tpr, thresholds, score\n",
      " |  \n",
      " |  shap_base_value(self, pos_label=None)\n",
      " |      SHAP base value: average outcome of population\n",
      " |  \n",
      " |  shap_interaction_values(self, pos_label=None)\n",
      " |      SHAP interaction values\n",
      " |  \n",
      " |  y_binary(self, pos_label)\n",
      " |      for multiclass problems returns one-vs-rest array of [1,0] pos_label\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  pos_label_str\n",
      " |      return str label of self.pos_label\n",
      " |  \n",
      " |  pred_percentiles_raw\n",
      " |  \n",
      " |  pred_probas_raw\n",
      " |      returns pred_probas with probability for each class\n",
      " |  \n",
      " |  shap_explainer\n",
      " |      Initialize SHAP explainer. \n",
      " |      \n",
      " |      Taking into account model type and model_output\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  pos_label\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseExplainer:\n",
      " |  \n",
      " |  __contains__(self, index)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  check_cats(*args, **kwargs)\n",
      " |  \n",
      " |  columns_ranked_by_shap(self, pos_label=None)\n",
      " |      returns the columns of X, ranked by mean abs shap value\n",
      " |      \n",
      " |      Args:\n",
      " |      cats: Group categorical together (Default value = False)\n",
      " |      pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |      list of columns\n",
      " |  \n",
      " |  contrib_df(*args, **kwargs)\n",
      " |  \n",
      " |  contrib_summary_df(*args, **kwargs)\n",
      " |  \n",
      " |  decision_path(*args, **kwargs)\n",
      " |  \n",
      " |  decision_path_encoded(*args, **kwargs)\n",
      " |  \n",
      " |  decision_path_file(*args, **kwargs)\n",
      " |  \n",
      " |  decisiontree_df(*args, **kwargs)\n",
      " |  \n",
      " |  decisiontree_summary_df(*args, **kwargs)\n",
      " |  \n",
      " |  description(self, col)\n",
      " |      returns the written out description of what feature col means\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): col to get description for\n",
      " |      \n",
      " |      Returns:\n",
      " |          str, description\n",
      " |  \n",
      " |  description_list(self, cols)\n",
      " |      returns a list of descriptions of a list of cols\n",
      " |      \n",
      " |      Args:\n",
      " |        cols(list): cols to be converted to descriptions\n",
      " |      \n",
      " |      Returns:\n",
      " |          list of descriptions\n",
      " |  \n",
      " |  dump(self, filepath)\n",
      " |      Dump the current Explainer to file. Depending on the suffix of the filepath \n",
      " |      will either dump with pickle ('.pkl'), dill ('.dill') or joblib ('joblib').\n",
      " |      \n",
      " |      If no suffix given, will dump with joblib and add '.joblib'\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath (str, Path): filepath where to save the Explainer.\n",
      " |  \n",
      " |  get_X_row(self, index, merge=False)\n",
      " |  \n",
      " |  get_col(self, col)\n",
      " |      return pd.Series with values of col\n",
      " |      \n",
      " |      For categorical feature reverse engineers the onehotencoding.\n",
      " |      \n",
      " |      Args:\n",
      " |        col: column tof values to be returned\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.Series with values of col\n",
      " |  \n",
      " |  get_col_value_plus_prediction(self, col, index=None, X_row=None, pos_label=None)\n",
      " |      return value of col and prediction for either index or X_row\n",
      " |      \n",
      " |      Args:\n",
      " |        col: feature col\n",
      " |        index (str or int, optional): index row\n",
      " |        X_row (single row pd.DataFrame, optional): single row of features\n",
      " |        pos_label (int): positive label\n",
      " |      \n",
      " |      Returns:\n",
      " |        value of col, prediction for index\n",
      " |  \n",
      " |  get_contrib_df(self, index=None, X_row=None, topx=None, cutoff=None, sort='abs', pos_label=None)\n",
      " |      shap value contributions to the prediction for index.\n",
      " |      \n",
      " |      Used as input for the plot_contributions() method.\n",
      " |      \n",
      " |      Args:\n",
      " |        index(int or str): index for which to calculate contributions\n",
      " |        X_row (pd.DataFrame, single row): single row of feature for which\n",
      " |              to calculate contrib_df. Can us this instead of index\n",
      " |        topx(int, optional, optional): Only return topx features, remainder \n",
      " |                  called REST, defaults to None\n",
      " |        cutoff(float, optional, optional): only return features with at least \n",
      " |                  cutoff contributions, defaults to None\n",
      " |        sort({'abs', 'high-to-low', 'low-to-high', 'importance'}, optional): sort by \n",
      " |                  absolute shap value, or from high to low, low to high, or\n",
      " |                  ordered by the global shap importances.\n",
      " |                  Defaults to 'abs'.\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame: contrib_df\n",
      " |  \n",
      " |  get_contrib_summary_df(self, index=None, X_row=None, topx=None, cutoff=None, round=2, sort='abs', pos_label=None)\n",
      " |      Takes a contrib_df, and formats it to a more human readable format\n",
      " |      \n",
      " |      Args:\n",
      " |        index: index to show contrib_summary_df for\n",
      " |        X_row (pd.DataFrame, single row): single row of feature for which\n",
      " |              to calculate contrib_df. Can us this instead of index\n",
      " |        topx: Only show topx highest features(Default value = None)\n",
      " |        cutoff: Only show features above cutoff (Default value = None)\n",
      " |        round: round figures (Default value = 2)\n",
      " |        sort({'abs', 'high-to-low', 'low-to-high', 'importance'}, optional): sort by \n",
      " |                  absolute shap value, or from high to low, or low to high, or\n",
      " |                  ordered by the global shap importances.\n",
      " |                  Defaults to 'abs'.\n",
      " |        pos_label: Positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame\n",
      " |  \n",
      " |  get_dfs(*args, **kwargs)\n",
      " |  \n",
      " |  get_idx(self, index)\n",
      " |      Turn str index into an int index\n",
      " |      \n",
      " |      Args:\n",
      " |        index(str or int): \n",
      " |      \n",
      " |      Returns:\n",
      " |          int index\n",
      " |  \n",
      " |  get_idx_sample(self, sample_size=None, include_index=None, outlier_array1=None, outlier_array2=None)\n",
      " |      returns a random sample of integer indexes, making sure that\n",
      " |      include_index is included. Outlier indexes can be excluded.\n",
      " |      \n",
      " |      Args:\n",
      " |          sample_size: Number of (random) samples to return\n",
      " |          include_index: index that has to be included, independent of random draw\n",
      " |          outlier_array1: array to exclude all indexes with values <> 1.5*IQR from.\n",
      " |          outlier_array2: array to exclude all indexes with values <> 1.5*IQR from.\n",
      " |  \n",
      " |  get_importances_df(self, kind='shap', topx=None, cutoff=None, pos_label=None)\n",
      " |      wrapper function for get_mean_abs_shap_df() and get_permutation_importance_df()\n",
      " |      \n",
      " |      Args:\n",
      " |        kind(str): 'shap' or 'permutations'  (Default value = \"shap\")\n",
      " |        topx: only display topx highest features (Default value = None)\n",
      " |        cutoff: only display features above cutoff (Default value = None)\n",
      " |        pos_label: Positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame\n",
      " |  \n",
      " |  get_index(self, index)\n",
      " |      Turn int index into a str index\n",
      " |      \n",
      " |      Args:\n",
      " |        index(str or int): \n",
      " |      \n",
      " |      Returns:\n",
      " |          str index\n",
      " |  \n",
      " |  get_index_list(self)\n",
      " |  \n",
      " |  get_int_idx(*args, **kwargs)\n",
      " |  \n",
      " |  get_interactions_df(self, col, topx=None, cutoff=None, pos_label=None)\n",
      " |      dataframe of mean absolute shap interaction values for col\n",
      " |      \n",
      " |      Args:\n",
      " |        col: Feature to get interactions_df for\n",
      " |        topx: Only display topx most important features (Default value = None)\n",
      " |        cutoff: Only display features with mean abs shap of at least cutoff (Default value = None)\n",
      " |        pos_label: Positive class  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame\n",
      " |  \n",
      " |  get_lock(self)\n",
      " |  \n",
      " |  get_mean_abs_shap_df(self, topx=None, cutoff=None, pos_label=None)\n",
      " |      sorted dataframe with mean_abs_shap\n",
      " |      \n",
      " |      returns a pd.DataFrame with the mean absolute shap values per features,\n",
      " |      sorted rom highest to lowest.\n",
      " |      \n",
      " |      Args:\n",
      " |        topx(int, optional, optional): Only return topx most importance \n",
      " |          features, defaults to None\n",
      " |        cutoff(float, optional, optional): Only return features with mean \n",
      " |          abs shap of at least cutoff, defaults to None\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame: shap_df\n",
      " |  \n",
      " |  get_permutation_importances_df(self, topx=None, cutoff=None, pos_label=None)\n",
      " |      dataframe with features ordered by permutation importance.\n",
      " |      \n",
      " |      For more about permutation importances.\n",
      " |      \n",
      " |      see https://explained.ai/rf-importance/index.html\n",
      " |      \n",
      " |      Args:\n",
      " |        topx(int, optional, optional): only return topx most important \n",
      " |              features, defaults to None\n",
      " |        cutoff(float, optional, optional): only return features with importance \n",
      " |              of at least cutoff, defaults to None\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        pd.DataFrame: importance_df\n",
      " |  \n",
      " |  get_prop_for_label(*args, **kwargs)\n",
      " |  \n",
      " |  get_row_from_input(self, inputs: List, ranked_by_shap=False, return_merged=False)\n",
      " |      returns a single row pd.DataFrame from a given list of *inputs\n",
      " |  \n",
      " |  get_y(self, index)\n",
      " |  \n",
      " |  index_exists(self, index)\n",
      " |  \n",
      " |  interactions_df(*args, **kwargs)\n",
      " |  \n",
      " |  memory_usage(self, cutoff=0)\n",
      " |      returns a pd.DataFrame witht the memory usage of each attribute of\n",
      " |      this explainer object\n",
      " |  \n",
      " |  ordered_cats(self, col, topx=None, sort='alphabet', pos_label=None)\n",
      " |      Return a list of categories in an categorical column, sorted\n",
      " |      by mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          col (str): Categorical feature to return categories for.\n",
      " |          topx (int, optional): Return topx top categories. Defaults to None.\n",
      " |          sort (str, optional): Sorting method, either alphabetically ('alphabet'),\n",
      " |              by frequency ('freq') or mean absolute shap ('shap'). \n",
      " |              Defaults to 'alphabet'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if sort is other than 'alphabet', 'freq', 'shap\n",
      " |      \n",
      " |      Returns:\n",
      " |          list\n",
      " |  \n",
      " |  pdp_df(self, col, index=None, X_row=None, drop_na=True, sample=500, n_grid_points=10, pos_label=None, sort='freq')\n",
      " |      Return a pdp_df for generating partial dependence plots.\n",
      " |      \n",
      " |      Args:\n",
      " |          col (str): Feature to generate partial dependence for.\n",
      " |          index ({int, str}, optional): Index to include on first row\n",
      " |              of pdp_df. Defaults to None.\n",
      " |          X_row (pd.DataFrame, optional): Single row to put on first row of pdp_df. \n",
      " |              Defaults to None.\n",
      " |          drop_na (bool, optional): Drop self.na_fill values. Defaults to True.\n",
      " |          sample (int, optional): Sample size for pdp_df. Defaults to 500.\n",
      " |          n_grid_points (int, optional): Number of grid points on x axis. \n",
      " |              Defaults to 10.\n",
      " |          pos_label ([type], optional): [description]. Defaults to None.\n",
      " |          sort (str, optional): For categorical features: how to sort:\n",
      " |           'alphabet', 'freq', 'shap'. Defaults to 'freq'.\n",
      " |      \n",
      " |      Returns:\n",
      " |          pd.DataFrame\n",
      " |  \n",
      " |  plot_contributions(self, index=None, X_row=None, topx=None, cutoff=None, sort='abs', orientation='vertical', higher_is_better=True, round=2, pos_label=None)\n",
      " |      plot waterfall plot of shap value contributions to the model prediction for index.\n",
      " |      \n",
      " |      Args:\n",
      " |          index(int or str): index for which to display prediction\n",
      " |          X_row (pd.DataFrame single row): a single row of a features to plot\n",
      " |              shap contributions for. Can use this instead of index for\n",
      " |              what-if scenarios.\n",
      " |          topx(int, optional, optional): Only display topx features, \n",
      " |                      defaults to None\n",
      " |          cutoff(float, optional, optional): Only display features with at least \n",
      " |                      cutoff contribution, defaults to None\n",
      " |          sort({'abs', 'high-to-low', 'low-to-high', 'importance'}, optional): \n",
      " |              sort by absolute shap value, or from high to low, \n",
      " |              or low to high, or by order of shap feature importance.\n",
      " |              Defaults to 'abs'.\n",
      " |          orientation({'vertical', 'horizontal'}): Horizontal or vertical bar chart. \n",
      " |                  Horizontal may be better if you have lots of features. \n",
      " |                  Defaults to 'vertical'.\n",
      " |          higher_is_better (bool): if True, up=green, down=red. If false reversed.\n",
      " |              Defaults to True.\n",
      " |          round(int, optional, optional): round contributions to round precision, \n",
      " |                      defaults to 2\n",
      " |          pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |          plotly.Fig: fig\n",
      " |  \n",
      " |  plot_dependence(self, col, color_col=None, highlight_index=None, topx=None, sort='alphabet', max_cat_colors=5, round=3, plot_sample=None, remove_outliers=False, pos_label=None)\n",
      " |      plot shap dependence\n",
      " |      \n",
      " |      Plots a shap dependence plot:\n",
      " |          - on the x axis the possible values of the feature `col`\n",
      " |          - on the y axis the associated individual shap values\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): feature to be displayed\n",
      " |        color_col(str): if color_col provided then shap values colored (blue-red) \n",
      " |                  according to feature color_col (Default value = None)\n",
      " |        highlight_index: individual observation to be highlighed in the plot. \n",
      " |                  (Default value = None)\n",
      " |        topx (int, optional): for categorical features only display topx\n",
      " |              categories.\n",
      " |        sort (str): for categorical features, how to sort the categories:\n",
      " |              alphabetically 'alphabet', most frequent first 'freq', \n",
      " |              highest mean absolute value first 'shap'. Defaults to 'alphabet'.\n",
      " |        max_cat_colors (int, optional): for categorical features, maximum number\n",
      " |              of categories to label with own color. Defaults to 5. \n",
      " |        round (int, optional): rounding to apply to floats. Defaults to 3.\n",
      " |        plot_sample (int, optional): Instead of all points only plot a random\n",
      " |          sample of points. Defaults to None (=all points)\n",
      " |        remove_outliers (bool, optional): remove observations that are >1.5*IQR \n",
      " |          in either col or color_col. Defaults to False.\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |  \n",
      " |  plot_importances(self, kind='shap', topx=None, round=3, pos_label=None)\n",
      " |      plot barchart of importances in descending order.\n",
      " |      \n",
      " |      Args:\n",
      " |        type(str, optional): shap' for mean absolute shap values, 'permutation' for\n",
      " |                  permutation importances, defaults to 'shap'\n",
      " |        topx(int, optional, optional): Only return topx features, defaults to None\n",
      " |        kind:  (Default value = 'shap')\n",
      " |        round:  (Default value = 3)\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly.fig: fig\n",
      " |  \n",
      " |  plot_importances_detailed(self, highlight_index=None, topx=None, max_cat_colors=5, plot_sample=None, pos_label=None)\n",
      " |      Plot barchart of mean absolute shap value.\n",
      " |      \n",
      " |      Displays all individual shap value for each feature in a horizontal\n",
      " |      scatter chart in descending order by mean absolute shap value.\n",
      " |      \n",
      " |      Args:\n",
      " |        highlight_index (str or int): index to highlight\n",
      " |        topx(int, optional): Only display topx most important features, \n",
      " |          defaults to None\n",
      " |        max_cat_colors (int, optional): for categorical features, maximum number\n",
      " |          of categories to label with own color. Defaults to 5. \n",
      " |        plot_sample (int, optional): Instead of all points only plot a random\n",
      " |          sample of points. Defaults to None (=all points)\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly.Fig\n",
      " |  \n",
      " |  plot_interaction(self, col, interact_col, highlight_index=None, topx=10, sort='alphabet', max_cat_colors=5, plot_sample=None, remove_outliers=False, pos_label=None)\n",
      " |      plots a dependence plot for shap interaction effects\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): feature for which to find interaction values\n",
      " |        interact_col(str): feature for which interaction value are displayed\n",
      " |        highlight_index(str, optional): index that will be highlighted, defaults to None\n",
      " |        topx (int, optional): number of categorical features to display in violin plots.\n",
      " |        sort (str, optional): how to sort categorical features in violin plots.\n",
      " |              Should be in {'alphabet', 'freq', 'shap'}.\n",
      " |        max_cat_colors (int, optional): for categorical features, maximum number\n",
      " |              of categories to label with own color. Defaults to 5. \n",
      " |        plot_sample (int, optional): Instead of all points only plot a random\n",
      " |          sample of points. Defaults to None (=all points)\n",
      " |        remove_outliers (bool, optional): remove observations that are >1.5*IQR \n",
      " |          in either col or color_col. Defaults to False.\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly.Fig: Plotly Fig\n",
      " |  \n",
      " |  plot_interactions(*args, **kwargs)\n",
      " |  \n",
      " |  plot_interactions_detailed(self, col, highlight_index=None, topx=None, max_cat_colors=5, plot_sample=None, pos_label=None)\n",
      " |      Plot barchart of mean absolute shap interaction values\n",
      " |      \n",
      " |      Displays all individual shap interaction values for each feature in a\n",
      " |      horizontal scatter chart in descending order by mean absolute shap value.\n",
      " |      \n",
      " |      Args:\n",
      " |        col(type]): feature for which to show interactions summary\n",
      " |        highlight_index (str or int): index to highlight\n",
      " |        topx(int, optional): only show topx most important features, defaults to None\n",
      " |        max_cat_colors (int, optional): for categorical features, maximum number\n",
      " |          of categories to label with own color. Defaults to 5. \n",
      " |        plot_sample (int, optional): Instead of all points only plot a random\n",
      " |          sample of points. Defaults to None (=all points)\n",
      " |        pos_label: positive class (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        fig\n",
      " |  \n",
      " |  plot_interactions_importance(self, col, topx=None, pos_label=None)\n",
      " |      plot mean absolute shap interaction value for col.\n",
      " |      \n",
      " |      Args:\n",
      " |        col: column for which to generate shap interaction value\n",
      " |        topx(int, optional, optional): Only return topx features, defaults to None\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly.fig: fig\n",
      " |  \n",
      " |  plot_pdp(self, col, index=None, X_row=None, drop_na=True, sample=100, gridlines=100, gridpoints=10, sort='freq', round=2, pos_label=None)\n",
      " |      plot partial dependence plot (pdp)\n",
      " |      \n",
      " |      returns plotly fig for a partial dependence plot showing ice lines\n",
      " |      for num_grid_lines rows, average pdp based on sample of sample.\n",
      " |      If index is given, display pdp for this specific index.\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): feature to display pdp graph for\n",
      " |        index(int or str, optional, optional): index to highlight in pdp graph, \n",
      " |                  defaults to None\n",
      " |        X_row (pd.Dataframe, single row, optional): a row of features to highlight \n",
      " |              predictions for. Alternative to passing index.\n",
      " |        drop_na(bool, optional, optional): if true drop samples with value \n",
      " |                  equal to na_fill, defaults to True\n",
      " |        sample(int, optional, optional): sample size on which the average \n",
      " |                  pdp will be calculated, defaults to 100\n",
      " |        gridlines(int, optional): number of ice lines to display, \n",
      " |                  defaults to 100\n",
      " |        gridpoints(ints: int, optional): number of points on the x axis \n",
      " |                  to calculate the pdp for, defaults to 10\n",
      " |        sort (str, optional): For categorical features: how to sort:\n",
      " |           'alphabet', 'freq', 'shap'. Defaults to 'freq'.\n",
      " |        round (int, optional): round float prediction to number of digits.\n",
      " |          Defaults to 2.\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        plotly.Fig: fig\n",
      " |  \n",
      " |  plot_shap_contributions(*args, **kwargs)\n",
      " |  \n",
      " |  plot_shap_dependence(*args, **kwargs)\n",
      " |  \n",
      " |  plot_shap_interaction(*args, **kwargs)\n",
      " |  \n",
      " |  plot_shap_interaction_summary(*args, **kwargs)\n",
      " |  \n",
      " |  plot_shap_summary(*args, **kwargs)\n",
      " |  \n",
      " |  set_X_row_func(self, func)\n",
      " |      Sets an external function to retrieve a row of input data a given index.\n",
      " |      \n",
      " |      func should either be a function that takes a single parameter: def func(index)\n",
      " |      or a method that takes a single parameter: def func(self, index)\n",
      " |  \n",
      " |  set_index_exists_func(self, func)\n",
      " |      Sets an external function to check whether an index is valid or not.\n",
      " |      \n",
      " |      func should either be a function that takes a single parameter: def func(index)\n",
      " |      or a method that takes a single parameter: def func(self, index)\n",
      " |  \n",
      " |  set_index_list_func(self, func)\n",
      " |      Sets an external function all available indexes from an external source.\n",
      " |      \n",
      " |      func should either be a parameterless function: def func(): ...\n",
      " |      or a parameterless method: def func(self): ...\n",
      " |  \n",
      " |  set_y_func(self, func)\n",
      " |      Sets an external function to retrieve an observed label for a given index.\n",
      " |      \n",
      " |      func should either be a function that takes a single parameter: def func(index)\n",
      " |      or a method that takes a single parameter: def func(self, index)\n",
      " |  \n",
      " |  shap_interaction_values_for_col(self, col, interact_col=None, pos_label=None)\n",
      " |      returns the shap interaction values[np.array(N,N)] for feature col\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): features for which you'd like to get the interaction value\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        np.array(N,N): shap_interaction_values\n",
      " |  \n",
      " |  shap_top_interactions(*args, **kwargs)\n",
      " |  \n",
      " |  to_sql(*args, **kwargs)\n",
      " |  \n",
      " |  to_yaml(self, filepath=None, return_dict=False, modelfile='model.pkl', datafile='data.csv', index_col=None, target_col=None, explainerfile='explainer.joblib', dashboard_yaml='dashboard.yaml')\n",
      " |      Returns a yaml configuration for the current Explainer\n",
      " |      that can be used by the explainerdashboard CLI. Recommended filename\n",
      " |      is `explainer.yaml`.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath ({str, Path}, optional): Filepath to dump yaml. If None\n",
      " |              returns the yaml as a string. Defaults to None.\n",
      " |          return_dict (bool, optional): instead of yaml return dict with config.\n",
      " |          modelfile (str, optional): filename of model dump. Defaults to\n",
      " |              `model.pkl`\n",
      " |          datafile (str, optional): filename of datafile. Defaults to\n",
      " |              `data.csv`.\n",
      " |          index_col (str, optional): column to be used for idxs. Defaults to\n",
      " |              self.idxs.name.\n",
      " |          target_col (str, optional): column to be used for to split X and y\n",
      " |              from datafile. Defaults to self.target.\n",
      " |          explainerfile (str, optional): filename of explainer dump. Defaults\n",
      " |              to `explainer.joblib`.\n",
      " |          dashboard_yaml (str, optional): filename of the dashboard.yaml\n",
      " |              configuration file. This will be used to determine which\n",
      " |              properties to calculate before storing to disk. \n",
      " |              Defaults to `dashboard.yaml`.\n",
      " |  \n",
      " |  top_shap_interactions(self, col, topx=None, pos_label=None)\n",
      " |      returns the features that interact with feature col in descending order.\n",
      " |      \n",
      " |      if shap interaction values have already been calculated, use those.\n",
      " |      Otherwise use shap approximate_interactions or simply mean abs shap.\n",
      " |      \n",
      " |      Args:\n",
      " |        col(str): feature for which you want to get the interactions\n",
      " |        topx(int, optional, optional): Only return topx features, defaults to None\n",
      " |        cats(bool, optional, optional): Group categorical features, defaults to False\n",
      " |        pos_label:  (Default value = None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        list: top_interactions\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from BaseExplainer:\n",
      " |  \n",
      " |  from_file(filepath) from abc.ABCMeta\n",
      " |      Load an Explainer from file. Depending on the suffix of the filepath \n",
      " |      will either load with pickle ('.pkl'), dill ('.dill') or joblib ('joblib').\n",
      " |      \n",
      " |      If no suffix given, will try with joblib.\n",
      " |      \n",
      " |      Args:\n",
      " |          filepath {str, Path} the location of the stored Explainer\n",
      " |          \n",
      " |      returns:\n",
      " |          Explainer object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseExplainer:\n",
      " |  \n",
      " |  X_cats\n",
      " |      X with categorical variables grouped together\n",
      " |  \n",
      " |  X_merged\n",
      " |  \n",
      " |  decision_trees\n",
      " |  \n",
      " |  feature_permutations_df\n",
      " |  \n",
      " |  importances_df\n",
      " |  \n",
      " |  n_features\n",
      " |      number of features \n",
      " |      \n",
      " |      Returns:\n",
      " |          int, number of features\n",
      " |  \n",
      " |  preds\n",
      " |      returns model model predictions\n",
      " |  \n",
      " |  shap_values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseExplainer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ClassifierExplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impossible-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fare', 'Age', 'PassengerClass', 'No_of_siblings_plus_spouses_on_board',\n",
       "       'No_of_parents_plus_children_on_board', 'Sex_female', 'Sex_male',\n",
       "       'Sex_nan', 'Deck_A', 'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F',\n",
       "       'Deck_G', 'Deck_T', 'Deck_Unkown', 'Embarked_Cherbourg',\n",
       "       'Embarked_Queenstown', 'Embarked_Southampton', 'Embarked_Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reverse-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"Sex\": \"Gender of passenger\",\n",
    "    \"Gender\": \"Gender of passenger\",\n",
    "    \"Deck\": \"The deck the passenger had their cabin on\",\n",
    "    \"PassengerClass\": \"The class of the ticket: 1st, 2nd or 3rd class\",\n",
    "    \"Fare\": \"The amount of money people paid\", \n",
    "    \"Embarked\": \"the port where the passenger boarded the Titanic. Either Southampton, Cherbourg or Queenstown\",\n",
    "    \"Age\": \"Age of the passenger\",\n",
    "    \"No_of_siblings_plus_spouses_on_board\": \"The sum of the number of siblings plus the number of spouses on board\",\n",
    "    \"No_of_parents_plus_children_on_board\" : \"The sum of the number of parents plus the number of children on board\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "coastal-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected RandomForestClassifier model: Changing class type to RandomForestClassifierExplainer...\n",
      "Note: model_output=='probability', so assuming that raw shap output of RandomForestClassifier is in probability space...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    }
   ],
   "source": [
    "explainer=ClassifierExplainer(model,x_test,y_test,cats=['Deck','Embarked',{'Gender':['Sex_male','Sex_female','Sex_nan']}],\\\n",
    "                              cats_notencoded={'Embarked':'Stoway'},descriptions=feature_descriptions,labels=['Not Survived','Survived'],\\\n",
    "                              index_name='Passenger',target='Survival')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sound-virus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Warning: calculating shap interaction values can be slow! Pass shap_interaction=False to remove interactions tab.\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Calculating dependencies...\n",
      "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
      "Calculating pred_percentiles...\n",
      "Calculating prediction probabilities...\n",
      "Calculating roc auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating predictions...\n",
      "Calculating pr auc curves...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n",
      "Calculating metrics...\n",
      "Calculating shap interaction values... (this may take a while)\n",
      "Reminder: TreeShap computational complexity is O(TLD^2), where T is the number of trees, L is the maximum number of leaves in any tree and D the maximal depth of any tree. So reducing these will speed up the calculation.\n",
      "Calculating ShadowDecTree for each individual decision tree...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "db=ExplainerDashboard(explainer,title='Model Explainer',sharp_interaction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.55.102:8080\n",
      "Dash is running on http://0.0.0.0:8080/\n",
      "\n",
      " * Serving Flask app \"explainerdashboard.dashboards\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /assets/bootstrap.min.css?m=1619336443.7712247 HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react@16.v1_9_1m1619336411.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_renderer/prop-types@15.v1_9_1m1619336411.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_renderer/polyfill@7.v1_9_1m1619336411.8.7.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react-dom@16.v1_9_1m1619336411.14.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_table/bundle.v4_11_3m1619336411.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_bootstrap_components/_components/dash_bootstrap_components.v0_12_0m1619336441.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components.v1_16_0m1619336412.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components-shared.v1_16_0m1619336412.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_html_components/dash_html_components.v1_1_3m1619336411.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:35] \"\u001b[37mGET /_dash-component-suites/dash_renderer/dash_renderer.v1_9_1m1619336411.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /assets/favicon.ico?m=1619336443.7712247 HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-dropdown.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-graph.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-plotlyjs.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:36] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.55.102 - - [25/Apr/2021 13:50:40] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:40] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:50:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:51:06] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:51:16] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:51:19] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:51:26] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:51:43] \"\u001b[37mGET /_dash-component-suites/dash_core_components/async-slider.v1_16_0m1617903285.js HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:33] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:35] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:41] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:42] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:43] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:46] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:52:47] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:56:40] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:56:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "192.168.55.102 - - [25/Apr/2021 13:56:57] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "db.run(8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
